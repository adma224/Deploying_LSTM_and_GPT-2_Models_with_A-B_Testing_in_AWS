{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8385cdb2-d8a2-4bbe-9a41-99af85930c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "from transformers import TrainingArguments\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdb21099-2769-4592-9941-656f28ab8626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...\n",
       "1  American Airlines Flyer Charged, Banned For Li...\n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...\n",
       "3  The Funniest Tweets From Parents This Week (Se...\n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"../data/cleaned_dataset.csv\", index_col=0)\n",
    "\n",
    "# Display the first few rows to confirm\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa1208c-2487-4ed9-833a-7d91cdb8244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # GPT-2 doesn't have padding by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3c30db-a4f2-4b68-9533-3bad9d61f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"headline\"])  # Remove rows where 'headline' is NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c887ae-60ab-4a55-aec6-2660bc04d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize headlines\n",
    "df[\"tokenized\"] = df[\"headline\"].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "\n",
    "# Find max sequence length\n",
    "max_length = max(len(tokens) for tokens in df[\"tokenized\"])\n",
    "\n",
    "# Pad sequences\n",
    "df[\"padded\"] = df[\"tokenized\"].apply(lambda x: x + [tokenizer.pad_token_id] * (max_length - len(x)))\n",
    "\n",
    "# Convert to tensor format\n",
    "input_ids = torch.tensor(df[\"padded\"].tolist(), dtype=torch.long)\n",
    "\n",
    "# Save processed dataset\n",
    "df.to_json(\"../data/gpt2_dataset.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065bb00-bb7d-44ad-90bf-2566aa67ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005f9808-4f52-4bef-afca-735bdb1b948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df.sample(n=20, random_state=42)  # Random 100 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b78f17-bab1-4bd9-82d5-e46243275944",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class GPT2Dataset(Dataset):\n",
    "    def __init__(self, df_subset):\n",
    "        self.input_ids = torch.tensor(df_subset[\"padded\"].tolist(), dtype=torch.long)\n",
    "        self.attention_mask = (self.input_ids != tokenizer.pad_token_id).long()  # Mask padding tokens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": self.input_ids[idx],  # GPT-2 is trained using its own inputs as labels\n",
    "        }\n",
    "\n",
    "# Train/Validation Split\n",
    "train_size = int(0.8 * len(df_subset))\n",
    "train_df, val_df = df[:train_size], df[train_size:]\n",
    "\n",
    "# Create Dataset\n",
    "train_dataset = GPT2Dataset(train_df)\n",
    "val_dataset = GPT2Dataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4957fd5d-1e0b-41d9-b49b-b1d459d09cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit GPU & CPU usage\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"  # Limit CPU threads\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0cbdb-3e15-4d7a-8808-a3c1ae096168",
   "metadata": {},
   "source": [
    "##### Choose a batch size and num workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc1028-e5e2-4fe1-a946-62d06d8334f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, num_workers=1, shuffle=True)  # Reduce num_workers\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, num_workers=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a319c04-bdcc-4476-9f43-d238d7d5c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.backends.cudnn.benchmark = False  # Reduce unnecessary optimizations\n",
    "torch.cuda.set_per_process_memory_fraction(0.6, device=0)  # Use only 80% of GPU memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b72c0-57f4-4d2f-8204-c9d1e9e185d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained GPT-2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load GPT-2 with LM head\n",
    "model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\")  # 50% smaller\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de360f98-e94e-4278-aea8-a25c603350b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Reduce batch size to prevent GPU memory issues\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"Model and data loaders ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c93fd8-df15-4f0a-b4d5-cde31fbdfdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free unused memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Limit memory usage (e.g., 50% of GPU capacity)\n",
    "torch.cuda.set_per_process_memory_fraction(0.5, device=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c348a2-6418-42e2-ac24-be7d2c6acbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Print selected device\n",
    "print(f\"üî• Using device: {device}\")\n",
    "\n",
    "# Print GPU info\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"üöÄ GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1024 ** 2:.2f} MB\")\n",
    "    print(f\"üíæ GPU Memory Reserved: {torch.cuda.memory_reserved(0) / 1024 ** 2:.2f} MB\")\n",
    "    print(f\"üîÑ CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"üñ• Running on CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e014f55-8bfc-4e86-8210-e87002b47232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # Where model checkpoints will be saved\n",
    "    logging_dir=\"./logs\",  # Directory for logging\n",
    "    logging_strategy=\"steps\",  # Log at every step\n",
    "    logging_steps=50,  # Log every 50 steps\n",
    "    report_to=[\"tensorboard\"],  # Log to TensorBoard\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate at each epoch\n",
    "    save_strategy=\"epoch\",  # Save model at each epoch\n",
    "    save_total_limit=2,  # Keep only last 2 checkpoints\n",
    "    disable_tqdm=False,  # Enable progress bars\n",
    "    load_best_model_at_end=True,  # Load best model checkpoint at end\n",
    "    fp16=True,  # Enable mixed precision for speed\n",
    "    per_device_train_batch_size=8,  # Adjust batch size to prevent memory issues\n",
    "    per_device_eval_batch_size=8,  # Same for evaluation\n",
    "    gradient_accumulation_steps=2,  # Accumulate gradients before updating weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a45e60-1d43-46bd-a44f-14c1bdc885b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set Hugging Face Transformers library to show debug logs\n",
    "transformers.logging.set_verbosity_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bbf9f5-e19e-4431-bcd8-93452750393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Hugging Face Trainer API\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e0b15-d114-40cd-929b-20fa08079cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure start time\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"üöÄ Training started...\")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb391b0-9ba0-4f35-975d-e0cdb062a908",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_duration = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432f471a-d540-4643-923e-50b18cbc1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print training duration\n",
    "print(f\"‚úÖ Training completed in {training_duration:.2f} seconds ({training_duration/60:.2f} minutes)\")\n",
    "\n",
    "# Monitor GPU usage\n",
    "if torch.cuda.is_available():\n",
    "    allocated_memory = torch.cuda.memory_allocated() / 1024**2  # Convert bytes to MB\n",
    "    reserved_memory = torch.cuda.memory_reserved() / 1024**2\n",
    "    print(f\"üíæ GPU Memory Allocated: {allocated_memory:.2f} MB\")\n",
    "    print(f\"üíæ GPU Memory Reserved: {reserved_memory:.2f} MB\")\n",
    "\n",
    "# Print final training state\n",
    "print(f\"üìà Final Epoch: {trainer.state.epoch}\")\n",
    "print(f\"üìä Total Training Steps: {trainer.state.global_step}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9f8a5a-2515-46c5-868d-b3722c8c099e",
   "metadata": {},
   "source": [
    "#### Run this command in the terminal for training metrics in tensorboard\n",
    "\n",
    "`tensorboard --logdir=./logs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca0ac8-8dc8-4724-8ced-0e35501cc4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model & tokenizer\n",
    "model.save_pretrained(\"../models/gpt2_finetuned\")\n",
    "tokenizer.save_pretrained(\"../models/gpt2_finetuned\")\n",
    "\n",
    "print(\"Model saved successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acff34e-359c-4243-85b2-d37316530fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(input_ids, max_length=max_length, pad_token_id=tokenizer.eos_token_id)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Test with example prompts\n",
    "examples = [\"Breaking news:\", \"Latest update:\", \"The president announced that\"]\n",
    "for text in examples:\n",
    "    print(f\"üìù Input: {text}\")\n",
    "    print(f\"üîÆ Output: {generate_text(text)}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba46cca-d050-4be2-a0c2-8f21754e3318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef089eb8-2c9d-4933-8c83-68d81b52298b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679dfdc-7afe-42ef-a236-aa2d6c893a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
