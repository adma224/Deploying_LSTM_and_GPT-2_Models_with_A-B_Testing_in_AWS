{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0504ce19",
   "metadata": {},
   "source": [
    "# Predicting the Next Token in Tweets Using LSTM and TensorFlow\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The ability to predict the next word or token in a sequence of text has significant implications for natural language processing (NLP) applications, including text completion, chatbots, and language translation. This project focuses on creating a machine learning model capable of predicting the next token in tweets. We leverage the power of Long Short-Term Memory (LSTM) networks, a type of recurrent neural network (RNN) that excels in learning order dependence in sequence prediction problems.\n",
    "\n",
    "Our dataset comprises preprocessed tweets, where each tweet has been cleaned and tokenized. Using TensorFlow, we build an LSTM model to learn these sequences and predict the next token based on the context provided by the previous tokens.\n",
    "\n",
    "The project is divided into several key sections:\n",
    "\n",
    "1. **Data Preparation:** Loading the preprocessed tweets, tokenizing the text, and preparing the sequences for training.\n",
    "2. **Model Building:** Constructing an LSTM model using TensorFlow to predict the next token.\n",
    "3. **Model Training:** Training our model on the prepared tweet sequences.\n",
    "4. **Evaluation and Testing:** Assessing the model's performance and conducting tests with custom inputs.\n",
    "5. **Model Saving and Deployment Preparation:** Saving the trained model and preparing it for deployment by containerizing it with Docker.\n",
    "6. **AWS Deployment Preparation:** Steps to upload the containerized model to Amazon Elastic Container Registry (ECR) for deployment on AWS SageMaker.\n",
    "\n",
    "By the end of this notebook, we will have a trained LSTM model ready for deployment, capable of predicting the next token in a sequence of tokens derived from tweets. This model serves as a foundation for more complex NLP tasks and demonstrates the process of moving from model training to deployment in a cloud environment.\n",
    "\n",
    "Let's get started by importing the necessary libraries and loading our data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7354dc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 18:56:00.857291: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-12 18:56:00.860049: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-12 18:56:00.905334: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-12 18:56:01.806534: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c226d827",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data\n",
    "\n",
    "Next, we load the preprocessed tweets and prepare them for training. This involves tokenizing the text data and creating sequences that will be used as input to our LSTM model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeee5429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>over  million americans roll up sleeves for om...</td>\n",
       "      <td>[   49   200   214  1960    43 19066     6 368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>american airlines flyer charged banned for lif...</td>\n",
       "      <td>[ 138 1087 9100  977 2082    6   63   27 8034 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of the funniest tweets about cats and dogs th...</td>\n",
       "      <td>[   3    1 1798  418   21 1701    7  663   19 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the funniest tweets from parents this week sept</td>\n",
       "      <td>[   1 1798  418   18  157   19   91 6910    0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>woman who called cops on black birdwatcher los...</td>\n",
       "      <td>[  126    50   857   481     9    82 28655  14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207991</th>\n",
       "      <td>rim ceo thorsten heins significant plans for b...</td>\n",
       "      <td>[11939   710 66968 66969  5191   735     6 132...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207992</th>\n",
       "      <td>maria sharapova stunned by victoria azarenka i...</td>\n",
       "      <td>[ 3706 13065  7235    37  3148 27076     5  20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207993</th>\n",
       "      <td>giants over patriots jets over colts among  mo...</td>\n",
       "      <td>[ 3528    49  4115  4664    49  8152   966    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207994</th>\n",
       "      <td>aldon smith arrested ers linebacker busted for...</td>\n",
       "      <td>[23500   984   515  5644 12332  4859     6  63...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207995</th>\n",
       "      <td>dwight howard rips teammates after magic loss ...</td>\n",
       "      <td>[12159  3041  1325 10004    27  1287   509    ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207996 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 headline  \\\n",
       "0       over  million americans roll up sleeves for om...   \n",
       "1       american airlines flyer charged banned for lif...   \n",
       "2        of the funniest tweets about cats and dogs th...   \n",
       "3        the funniest tweets from parents this week sept    \n",
       "4       woman who called cops on black birdwatcher los...   \n",
       "...                                                   ...   \n",
       "207991  rim ceo thorsten heins significant plans for b...   \n",
       "207992  maria sharapova stunned by victoria azarenka i...   \n",
       "207993  giants over patriots jets over colts among  mo...   \n",
       "207994  aldon smith arrested ers linebacker busted for...   \n",
       "207995  dwight howard rips teammates after magic loss ...   \n",
       "\n",
       "                                                   padded  \n",
       "0       [   49   200   214  1960    43 19066     6 368...  \n",
       "1       [ 138 1087 9100  977 2082    6   63   27 8034 ...  \n",
       "2       [   3    1 1798  418   21 1701    7  663   19 ...  \n",
       "3       [   1 1798  418   18  157   19   91 6910    0 ...  \n",
       "4       [  126    50   857   481     9    82 28655  14...  \n",
       "...                                                   ...  \n",
       "207991  [11939   710 66968 66969  5191   735     6 132...  \n",
       "207992  [ 3706 13065  7235    37  3148 27076     5  20...  \n",
       "207993  [ 3528    49  4115  4664    49  8152   966    ...  \n",
       "207994  [23500   984   515  5644 12332  4859     6  63...  \n",
       "207995  [12159  3041  1325 10004    27  1287   509    ...  \n",
       "\n",
       "[207996 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "df = pd.read_csv('../data/lstm_dataset.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "917646a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <class 'str'>\n",
       "1    <class 'str'>\n",
       "2    <class 'str'>\n",
       "3    <class 'str'>\n",
       "4    <class 'str'>\n",
       "5    <class 'str'>\n",
       "6    <class 'str'>\n",
       "7    <class 'str'>\n",
       "8    <class 'str'>\n",
       "9    <class 'str'>\n",
       "Name: padded, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['padded'].head(10).apply(type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71285932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input_sequences: (207996, 43)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert NumPy-style string lists to actual lists\n",
    "df['padded'] = df['padded'].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \").astype(int).tolist() if isinstance(x, str) else x)\n",
    "\n",
    "# Convert into a proper NumPy 2D array\n",
    "input_sequences = np.array(df['padded'].tolist(), dtype=np.int32)\n",
    "\n",
    "# Verify the shape\n",
    "print(\"Shape of input_sequences:\", input_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ef47503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate predictors (X) and labels (y)\n",
    "X, y = input_sequences[:,:-1], input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efc03700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GloVe embeddings file\n",
    "glove_path = \"../data/glove.6B.100d.txt\"  # Download from https://nlp.stanford.edu/projects/glove/\n",
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d475244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors from GloVe.\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary mapping words to their embedding vectors\n",
    "embeddings_index = {}\n",
    "\n",
    "with open(glove_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]  # First item is the word\n",
    "        coefs = np.asarray(values[1:], dtype=\"float32\")  # The rest are embedding values\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f\"Loaded {len(embeddings_index)} word vectors from GloVe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2daccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a82cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada42797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6672b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8c364dc",
   "metadata": {},
   "source": [
    "## 3. Build the LSTM Model\n",
    "\n",
    "With our data prepared, we can now build the LSTM model. We use an Embedding layer to learn token embeddings, followed by an LSTM layer and a Dense layer for prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9126632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c74a3e",
   "metadata": {},
   "source": [
    "## 4. Compile the Model\n",
    "\n",
    "We compile the model using the 'adam' optimizer and 'categorical_crossentropy' as the loss function, suitable for multi-class classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27775f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eceed5",
   "metadata": {},
   "source": [
    "## 5. Train the Model\n",
    "\n",
    "It's time to train our model. Note that this process can be time-consuming, depending on the size of your data and the complexity of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e4d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(predictors, label, epochs=100, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5116211",
   "metadata": {},
   "source": [
    "## 6. Evaluate the Model\n",
    "\n",
    "After training, we can evaluate our model's performance and plot the training history to visualize the learning process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0914850c",
   "metadata": {},
   "source": [
    "## 7. Test the Model\n",
    "\n",
    "Finally, let's test our model with a custom input to predict the next token in a sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf05db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_token(seed_text):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    return tokenizer.index_word[predicted[0]]\n",
    "\n",
    "# Test with a custom input\n",
    "seed_text = \"I feel\"\n",
    "next_token = predict_next_token(seed_text)\n",
    "print(f\"Next token after '{seed_text}': {next_token}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee283b6",
   "metadata": {},
   "source": [
    "## 8. Save the Model\n",
    "\n",
    "To deploy the model, we first need to save it. TensorFlow provides a simple API to save models in the SavedModel format, which can be easily served in different environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc23e78d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_model/next_token_predictor\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39msave(model_save_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_save_path = 'saved_model/next_token_predictor'\n",
    "model.save(model_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a2f012",
   "metadata": {},
   "source": [
    "## 9. Containerize the Model Using Docker\n",
    "\n",
    "To prepare our model for deployment on AWS SageMaker, we'll containerize it using Docker. This process involves creating a Dockerfile, building a Docker image, and testing it locally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291e37da",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2872726390.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    FROM tensorflow/serving\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Create a Dockerfile\n",
    "\n",
    "FROM tensorflow/serving\n",
    "\n",
    "# Copy the model to the container\n",
    "COPY ${model_save_path} /models/next_token_predictor/1\n",
    "\n",
    "# Set environment variables to serve the model\n",
    "ENV MODEL_NAME=next_token_predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac32721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Docker image\n",
    "docker build -t next-token-predictor:latest .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3938bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Docker container locally to test\n",
    "docker run -p 8501:8501 --name=my_model_container next-token-predictor:latest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97790e07",
   "metadata": {},
   "source": [
    "## 10. Upload the Model to Amazon ECR\n",
    "\n",
    "For deploying our model with AWS SageMaker, we need to upload our Docker container to Amazon Elastic Container Registry (ECR). This section outlines the steps to create a repository in ECR, authenticate Docker to push images to ECR, and finally, push the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af59dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Set your AWS region\n",
    "aws_region = 'us-west-2'\n",
    "ecr_repository_name = 'next-token-predictor'\n",
    "\n",
    "# Create ECR client\n",
    "ecr_client = boto3.client('ecr', region_name=aws_region)\n",
    "\n",
    "# Create an ECR repository\n",
    "response = ecr_client.create_repository(repositoryName=ecr_repository_name)\n",
    "repository_uri = response['repository']['repositoryUri']\n",
    "\n",
    "print(f\"Repository URI: {repository_uri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate Docker to push to ECR\n",
    "aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin <repository_uri>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag your Docker image with the ECR repository URI\n",
    "docker tag next-token-predictor:latest <repository_uri>:latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136a8154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push the Docker image to ECR\n",
    "docker push <repository_uri>:latest\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
