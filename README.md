# ðŸ“¦ A/B Model Inference Pipeline with AWS CDK and CI/CD

This project demonstrates a scalable, production-style A/B inference pipeline using AWS CDK, Lambda, API Gateway, and SageMaker. It includes a fully automated CI/CD pipeline powered by GitHub Actions and is designed to showcase mid-level skills in AWS Cloud Engineering, DevOps, Machine Learning Engineering, and MLOps.

---

## ðŸ§  Project Goals

- Deploy and manage multiple ML models using AWS SageMaker
- Route inference requests using an A/B testing mechanism
- Automate infrastructure and deployment using AWS CDK
- Collect and analyze feedback to evaluate model performance
- Implement CI/CD best practices using GitHub Actions
- Gradually scale to include training, model versioning, and evaluation

---

## ðŸš€ Live Project Phases

This is a multi-phase portfolio project. Each phase adds production-level capabilities:

| Phase | Description |
|-------|-------------|
| Phase 1 | Deploy GPT-2 to SageMaker manually |
| Phase 2 | Add GitHub Actions pipeline for CI/CD |
| Phase 3 | Deploy Lambda function to invoke SageMaker |
| Phase 4 | Expose public API via API Gateway + Route 53 |
| Phase 5 | Add second model + inference routing (A/B) |
| Phase 6 | Collect feedback with DynamoDB |
| Phase 7 | Add visualization and metric reporting |
| Phase 8 | Add SageMaker training job pipeline |
| Phase 9 | Register models and deploy versioned models |

---

## ðŸ§° Tech Stack

**Cloud Infrastructure**
- AWS CDK (Python)
- AWS Lambda
- Amazon SageMaker
- Amazon API Gateway
- Amazon Route 53
- Amazon DynamoDB
- AWS IAM
- Amazon CloudWatch

**CI/CD & DevOps**
- GitHub Actions
- AWS CLI
- CDK Synth/Deploy
- Flake8 + Pytest
- Secrets Management

**Machine Learning**
- HuggingFace Transformers (GPT-2, GPT-Lite)
- PyTorch / Transformers
- Evaluation logging
- A/B testing logic

---

